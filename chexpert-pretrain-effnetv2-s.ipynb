{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import beepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os \n",
    "import PIL\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import warnings\n",
    "import config\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chexpert_train_image_paths.txt',\n",
       " 'chexpert_valid_image_paths.txt',\n",
       " 'train',\n",
       " 'train.csv',\n",
       " 'valid',\n",
       " 'valid.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = pathlib.Path(config.CHEXPERT_DATA_PATH)\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "valid_df = pd.read_csv(os.path.join(data_dir, 'valid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>68</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>87</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>83</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>83</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path     Sex  Age  \\\n",
       "0  CheXpert-v1.0-small/train/patient00001/study1/...  Female   68   \n",
       "1  CheXpert-v1.0-small/train/patient00002/study2/...  Female   87   \n",
       "2  CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
       "3  CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
       "4  CheXpert-v1.0-small/train/patient00003/study1/...    Male   41   \n",
       "\n",
       "  Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
       "0         Frontal    AP         1.0                         NaN           NaN   \n",
       "1         Frontal    AP         NaN                         NaN          -1.0   \n",
       "2         Frontal    AP         NaN                         NaN           NaN   \n",
       "3         Lateral   NaN         NaN                         NaN           NaN   \n",
       "4         Frontal    AP         NaN                         NaN           NaN   \n",
       "\n",
       "   Lung Opacity  Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
       "0           NaN          NaN    NaN            NaN        NaN          NaN   \n",
       "1           1.0          NaN   -1.0           -1.0        NaN         -1.0   \n",
       "2           1.0          NaN    NaN           -1.0        NaN          NaN   \n",
       "3           1.0          NaN    NaN           -1.0        NaN          NaN   \n",
       "4           NaN          NaN    1.0            NaN        NaN          NaN   \n",
       "\n",
       "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \n",
       "0           0.0               NaN            NaN       NaN              1.0  \n",
       "1           NaN              -1.0            NaN       1.0              NaN  \n",
       "2           NaN               NaN            NaN       1.0              NaN  \n",
       "3           NaN               NaN            NaN       1.0              NaN  \n",
       "4           0.0               NaN            NaN       NaN              NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 223414 entries, 0 to 223413\n",
      "Data columns (total 19 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Path                        223414 non-null  object \n",
      " 1   Sex                         223414 non-null  object \n",
      " 2   Age                         223414 non-null  int64  \n",
      " 3   Frontal/Lateral             223414 non-null  object \n",
      " 4   AP/PA                       191027 non-null  object \n",
      " 5   No Finding                  22381 non-null   float64\n",
      " 6   Enlarged Cardiomediastinum  44839 non-null   float64\n",
      " 7   Cardiomegaly                46203 non-null   float64\n",
      " 8   Lung Opacity                117778 non-null  float64\n",
      " 9   Lung Lesion                 11944 non-null   float64\n",
      " 10  Edema                       85956 non-null   float64\n",
      " 11  Consolidation               70622 non-null   float64\n",
      " 12  Pneumonia                   27608 non-null   float64\n",
      " 13  Atelectasis                 68443 non-null   float64\n",
      " 14  Pneumothorax                78934 non-null   float64\n",
      " 15  Pleural Effusion            133211 non-null  float64\n",
      " 16  Pleural Other               6492 non-null    float64\n",
      " 17  Fracture                    12194 non-null   float64\n",
      " 18  Support Devices             123217 non-null  float64\n",
      "dtypes: float64(14), int64(1), object(4)\n",
      "memory usage: 32.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 234 entries, 0 to 233\n",
      "Data columns (total 19 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Path                        234 non-null    object \n",
      " 1   Sex                         234 non-null    object \n",
      " 2   Age                         234 non-null    int64  \n",
      " 3   Frontal/Lateral             234 non-null    object \n",
      " 4   AP/PA                       202 non-null    object \n",
      " 5   No Finding                  234 non-null    float64\n",
      " 6   Enlarged Cardiomediastinum  234 non-null    float64\n",
      " 7   Cardiomegaly                234 non-null    float64\n",
      " 8   Lung Opacity                234 non-null    float64\n",
      " 9   Lung Lesion                 234 non-null    float64\n",
      " 10  Edema                       234 non-null    float64\n",
      " 11  Consolidation               234 non-null    float64\n",
      " 12  Pneumonia                   234 non-null    float64\n",
      " 13  Atelectasis                 234 non-null    float64\n",
      " 14  Pneumothorax                234 non-null    float64\n",
      " 15  Pleural Effusion            234 non-null    float64\n",
      " 16  Pleural Other               234 non-null    float64\n",
      " 17  Fracture                    234 non-null    float64\n",
      " 18  Support Devices             234 non-null    float64\n",
      "dtypes: float64(14), int64(1), object(4)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "source": [
    "valid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    CheXpert-v1.0-small/train/patient00001/study1/...\n",
       "1    CheXpert-v1.0-small/train/patient00002/study2/...\n",
       "2    CheXpert-v1.0-small/train/patient00002/study1/...\n",
       "3    CheXpert-v1.0-small/train/patient00002/study1/...\n",
       "4    CheXpert-v1.0-small/train/patient00003/study1/...\n",
       "Name: Path, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[:5,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing NaN values for the 14 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No Finding',\n",
       " 'Enlarged Cardiomediastinum',\n",
       " 'Cardiomegaly',\n",
       " 'Lung Opacity',\n",
       " 'Lung Lesion',\n",
       " 'Edema',\n",
       " 'Consolidation',\n",
       " 'Pneumonia',\n",
       " 'Atelectasis',\n",
       " 'Pneumothorax',\n",
       " 'Pleural Effusion',\n",
       " 'Pleural Other',\n",
       " 'Fracture',\n",
       " 'Support Devices']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing all the NaN values in train and validation dataframes with 0.0 for the 14 labels\n",
    "label_columns = list(train_df.iloc[:5, 5:].columns)\n",
    "label_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[:, label_columns] = train_df.loc[:, label_columns].replace(to_replace = np.nan, value = 0.0)\n",
    "\n",
    "valid_df.loc[:, label_columns] = valid_df.loc[:, label_columns].replace(to_replace = np.nan, value= 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing uncertain labels with positive labels\n",
    "def uncertain_to_pos(df):\n",
    "    df.replace(to_replace = -1.0, value = 1.0, inplace = True)\n",
    "\n",
    "uncertain_to_pos(train_df)\n",
    "uncertain_to_pos(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.set_index('Path', inplace = True)\n",
    "valid_df.set_index('Path', inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chexpert_train_image_paths.txt', 'r') as file:\n",
    "    train_image_paths = file.readline()\n",
    "with open('chexpert_valid_image_paths.txt', 'r') as file:\n",
    "    valid_image_paths = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "train_image_paths = ast.literal_eval(train_image_paths)\n",
    "valid_image_paths = ast.literal_eval(valid_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_path(path):\n",
    "    parts = path.split('/')[4:]\n",
    "    new_path = os.path.join(data_dir, os.path.join(*parts))\n",
    "    return new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths = Parallel(n_jobs= 10, backend = 'threading')(delayed(modify_path)(path) for path in train_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_image_paths = Parallel(n_jobs= 10, backend = 'threading')(delayed(modify_path)(path) for path in valid_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Datasets\\\\CheXpert-v1.0-small\\\\train\\\\patient00734\\\\study3\\\\view2_lateral.jpg',\n",
       " 'D:\\\\Datasets\\\\CheXpert-v1.0-small\\\\train\\\\patient00734\\\\study3\\\\view1_frontal.jpg',\n",
       " 'D:\\\\Datasets\\\\CheXpert-v1.0-small\\\\train\\\\patient00734\\\\study2\\\\view1_frontal.jpg',\n",
       " 'D:\\\\Datasets\\\\CheXpert-v1.0-small\\\\train\\\\patient00734\\\\study1\\\\view1_frontal.jpg',\n",
       " 'D:\\\\Datasets\\\\CheXpert-v1.0-small\\\\train\\\\patient28598\\\\study3\\\\view1_frontal.jpg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths.remove('D:\\\\Datasets\\\\CheXpert-v1.0-small\\\\train\\\\patient00001\\\\study1\\\\._view1_frontal.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(train_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(train_image_paths)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(valid_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = tf.data.experimental.cardinality(train_ds).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(image_count * 0.5)\n",
    "train_final_ds = train_ds.skip(val_size)\n",
    "val_ds = train_ds.take(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.concat([train_df, valid_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height, input_width = (512,512)\n",
    "def process_path(file_path):\n",
    "    parts = list(tf.strings.split(file_path, os.path.sep).numpy()[-5:])\n",
    "    parts = [i.decode() for i in parts]\n",
    "    min_path = '/'.join(parts)\n",
    "    label = tf.cast(list(main_df.loc[min_path,label_columns]), dtype = tf.int16)\n",
    "    \n",
    "    # Loading the image\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(img, channels = 1)\n",
    "    # Resizing the image\n",
    "    img = tf.image.resize(img, [input_height,input_width])\n",
    "    img =  tf.image.grayscale_to_rgb(img)\n",
    "#     img = tf.cast(img, dtype = tf.int16)\n",
    "    img = tf.keras.applications.mobilenet.preprocess_input(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_final_ds = train_final_ds.map(lambda x: tf.py_function(func = process_path,inp = [x], Tout = (tf.float32, tf.int16)), num_parallel_calls = tf.data.AUTOTUNE)\n",
    "valid_ds = val_ds.map(lambda x: tf.py_function(func = process_path,inp = [x], Tout = (tf.float32, tf.int16)), num_parallel_calls = tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(lambda x: tf.py_function(func = process_path,inp = [x], Tout = (tf.float32, tf.int16)), num_parallel_calls = tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train = train_final_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "valid = valid_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test = test_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNetV2 - S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "effnet_path = os.path.join(os.getcwd(), 'automl', 'efficientnetv2')\n",
    "sys.path.append(effnet_path)\n",
    "import effnetv2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_scheduler = tf.keras.optimizers.schedules.CosineDecayRestarts(initial_learning_rate=0.0001, \n",
    "                                                  first_decay_steps=1000,\n",
    "                                                  alpha = 0.02,\n",
    "                                                  m_mul=0.9, \n",
    "                                                  t_mul = 2  \n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetv2-s (EffNetV2Mo (None, 1280)              20331360  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 14)                17934     \n",
      "=================================================================\n",
      "Total params: 20,349,294\n",
      "Trainable params: 20,195,422\n",
      "Non-trainable params: 153,872\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "effnetv2_s = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=[input_height,input_width, 3]),\n",
    "    effnetv2_model.get_model('efficientnetv2-s', include_top=False, pretrained=False),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(14, activation='sigmoid'),\n",
    "])\n",
    "effnetv2_s.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate_scheduler,)\n",
    "\n",
    "effnetv2_s.compile(optimizer=optimizer, loss = tf.keras.losses.CategoricalCrossentropy(), metrics = [tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './checkpoints/train/efficientNetV2-s/512px'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(min_delta = 0.0001, patience = 2)\n",
    "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor = 0.1, patience = 1)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only = True)\n",
    "callbacks = [early_stopping, checkpoint]\n",
    "checkpoint._supports_tf_logs = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'effnetv2_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5da6b3a7583b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meffnetv2_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'effnetv2_s' is not defined"
     ]
    }
   ],
   "source": [
    "effnetv2_s.fit(train,validation_data=test, epochs = 10, callbacks=callbacks, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#effnetv2_s.save(r'C:\\Users\\prans\\Python files\\Kaggle Competitions\\Covid_19_object_detection\\saved_models\\efficientNetV2-s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid_19",
   "language": "python",
   "name": "covid_19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
